{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from math import ceil\n",
    "from functools import reduce\n",
    "from collections import namedtuple\n",
    "from queue import PriorityQueue\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_SIZE = 15\n",
    "NUM_SETS = 30\n",
    "SETS = tuple(np.array([random() < 0.25 for _ in range(PROBLEM_SIZE)]) for _ in range(NUM_SETS)) #Set are created randomly, 25% true 75% false\n",
    "\n",
    "State = namedtuple('State', ['taken', 'not_taken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "def check_super_sets():   #I check if there are sets with all True or all False values\n",
    "    filtered_sets = tuple(filter(any, SETS)) \n",
    "    all_true_sets = tuple(filter(all, SETS)) \n",
    "    return filtered_sets, all_true_sets \n",
    " \n",
    "filtered_sets, all_true_sets = check_super_sets() #filtered sets without sets with all false\n",
    "if(len(all_true_sets) != 0): \n",
    "    print(\"Problem solvable with only one set\") \n",
    "NUM_FSETS = len(filtered_sets)  #number of filtered sets without sets with all false\n",
    "print(NUM_FSETS) \n",
    "#print(filtered_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covered(state):\n",
    "    return reduce(\n",
    "        np.logical_or,\n",
    "        [filtered_sets[i] for i in state.taken],\n",
    "        np.array([False for _ in range(PROBLEM_SIZE)]),\n",
    "    )\n",
    "\n",
    "def goal_check(state):\n",
    "    return np.all(covered(state))\n",
    "\n",
    "assert goal_check(State(set(range(NUM_FSETS)), set())), \"Probelm not solvable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The estimates of these heuristics may not be optimal but they provide a reasonable estimate of the number of sets needed to cover the remaining elements.\n",
    "def h_largest_set(state):\n",
    "    largest_set_size = max(sum(s) for s in filtered_sets) \n",
    "    missing_size = PROBLEM_SIZE - sum(covered(state))\n",
    "    optimistic_estimate = ceil(missing_size / largest_set_size) #with this optimistic estimate you hope that the largest_set_size hasn't the same nodes that you have already taken\n",
    "    return optimistic_estimate\n",
    "\n",
    "\n",
    "def h2_largest_uncovered_set(state):\n",
    "    already_covered = covered(state)  #remove the taken nodes before considering the largest_set_size available!\n",
    "    if np.all(already_covered):\n",
    "        return 0\n",
    "    largest_set_size = max(sum(np.logical_and(s, np.logical_not(already_covered))) for s in filtered_sets)\n",
    "    missing_size = PROBLEM_SIZE - sum(already_covered)\n",
    "    optimistic_estimate = ceil(missing_size / largest_set_size)  #Calculate an optimistic estimate of the number of sets needed to cover the remaining elements. Division of the number of missing elements by the size of the largest subset \n",
    "    return optimistic_estimate\n",
    "\n",
    "\n",
    "def h3_select_powerful_set(state):   #remove the taken nodes before considering the largest_set_size available and then ordered them descendently!\n",
    "    already_covered = covered(state)  \n",
    "    if np.all(already_covered):\n",
    "        return 0\n",
    "    missing_size = PROBLEM_SIZE - sum(already_covered)\n",
    "    candidates = sorted((sum(np.logical_and(s, np.logical_not(already_covered))) for s in filtered_sets), reverse=True)\n",
    "    taken = 1\n",
    "    while sum(candidates[:taken]) < missing_size: #calculate how many of the candidates subsets must be selected (taken) so that the sum of their element-covering capacities is sufficient to cover all the missing elements.\n",
    "        taken += 1                                #increments the value of taken until the sum of the first taken subsets is sufficient to cover all the missing elements.\n",
    "    return taken\n",
    "# With h3 as heuristic function we obtain an improvement of 4 orders of magnitude compared to breadth first\n",
    "\n",
    "\n",
    "#h4 is halfway between h2 and h3. The main difference is that h3 sorts the subsets in descending order by the number of uncovered elements that each subset covers,\n",
    "#while h4 sorts the subsets in descending order by the total number of elements covered by each subset(as h2). But at the end use the same strategy of h3 with the variable taken\n",
    "#This function is slower than h3 and h2, and it can take also 2 minutes for unlucky sets (using PROBLEM_SIZE=20 and NUM_SETS=40).It also shows how write code usign numpy arrays help the performance\n",
    "def h4_max_elements_covered(state):\n",
    "    already_covered = covered(state)\n",
    "    if np.all(already_covered):\n",
    "        return 0\n",
    "    missing_size = PROBLEM_SIZE - sum(already_covered)\n",
    "    \n",
    "    elements_covered_by_set = [sum(s) for s in filtered_sets] # Calculate the number of elements covered by each subset\n",
    "    sorted_sets = sorted(enumerate(elements_covered_by_set), key=lambda x: x[1], reverse=True) #Sort subsets by number of elements covered (descending)\n",
    "    \n",
    "    taken = 0\n",
    "    total_elements_covered = 0\n",
    "    \n",
    "    for i, num_elements_covered in sorted_sets:\n",
    "        if total_elements_covered + num_elements_covered < missing_size:\n",
    "            total_elements_covered += num_elements_covered\n",
    "            taken += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return taken\n",
    "\n",
    "def f(state):\n",
    "    return len(state.taken) + h3_select_powerful_set(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved in 20 steps (3 tiles)\n"
     ]
    }
   ],
   "source": [
    "frontier = PriorityQueue()  \n",
    "state = State(set(), set(range(NUM_FSETS)))\n",
    "frontier.put((f(state), state))\n",
    "\n",
    "counter = 0\n",
    "_, current_state = frontier.get()\n",
    "while not goal_check(current_state):\n",
    "        counter += 1\n",
    "        for action in current_state[1]:\n",
    "            new_state = State(\n",
    "                current_state.taken ^ {action},\n",
    "                current_state.not_taken ^ {action},\n",
    "            )\n",
    "            frontier.put((f(new_state), new_state))\n",
    "        _, current_state = frontier.get()\n",
    "    \n",
    "print(f\"Solved in {counter:,} steps ({len(current_state.taken)} tiles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(taken={17, 3, 20}, not_taken={0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
